{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-xxx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector similarity recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase, basic_auth\n",
    "\n",
    "driver = GraphDatabase.driver(\n",
    "    \"bolt://localhost:7687\",\n",
    "  auth=basic_auth(\"neo4j\", \"$$1234bala\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_title = \"The Matrix\"\n",
    "# current_title = \"The Great Gatsby\"\n",
    "\n",
    "vector_similarity = '''\n",
    "match (m:Movie { title: $Title })\n",
    "call db.index.vector.queryNodes('desc-embeddings', $top_k, m.embedding)\n",
    "yield node AS similarDesc, score\n",
    "where  similarDesc <> m\n",
    "return similarDesc.title as title, similarDesc.description as desc, score\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Related Movies: \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with driver.session(database=\"neo4j\") as session:\n",
    "  results = session.execute_read(lambda tx: tx.run(vector_similarity, Title=current_title, top_k=k).data() )\n",
    "  #results = session.read_transaction(lambda tx: tx.run(vector_similarity, top_k=k).data() )\n",
    "  context = \"Related Movies: \\n\\n\" + \"\\n\\n\".join([\"title: \" + record['title'] + \"\\n\" + \"Description: \" + record['desc'] + \"\\n\" for record in results ])\n",
    "\n",
    "driver.close()\n",
    "\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "template = \"\"\"I've read an article titled {current_movie_title}.\n",
    "Tell me what should I read next and a brief description of why based only on the provided context.\n",
    "\n",
    "{context}\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "theprompt = prompt.format_prompt(current_movie_title=current_title,context=context)\n",
    "\n",
    "#print(theprompt)\n",
    "\n",
    "llm(theprompt.to_messages())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph similarity recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase, basic_auth\n",
    "\n",
    "driver = GraphDatabase.driver(\n",
    "    \"bolt://localhost:7687\",\n",
    "  auth=basic_auth(\"neo4j\", \"$$1234bala\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_title = \"Performance Testing Neo4j Database using Bolt Protocol in Apache JMeter\"\n",
    "current_uri = \"https://dev.to/qainsights/performance-testing-neo4j-database-using-bolt-protocol-in-apache-jmeter-1oa9\"\n",
    "\n",
    "graph_similarity = '''\n",
    "match (a:Article { uri: $uri})-[rt1:refers_to]->(c1)\n",
    "call n10s.sim.pathsim.search(c1,0.2,{ simulateRoot: false }) yield node as relatedTopic\n",
    "with a,c1,collect(relatedTopic) + [c1] as topics\n",
    "unwind topics as c2\n",
    "match (similarArticle:Article )-[rt2:refers_to]->(c2) //where similarArticle <> a\n",
    "with a.title as original, similarArticle.title as similar,\n",
    "[x in collect(n10s.sim.pathsim.value(c1,c2, { simulateRoot: false})) where x > 0 ] as sims ,\n",
    "collect(n10s.sim.pathsim.path(c1,c2, { simulateRoot: false})) as paths,\n",
    "collect([\"the original article mentions explicitly \" + nodes(n10s.sim.pathsim.path(c1,c2, { simulateRoot: false}))[0].prefLabel ]  +\n",
    " [\" the recommended article mentions explicitly \" + nodes(n10s.sim.pathsim.path(c1,c2, { simulateRoot: false}))[-1].prefLabel]  + [r in relationships(n10s.sim.pathsim.path(c1,c2, { simulateRoot: false})) | startNode(r).prefLabel + \" is a type of \" + endNode(r).prefLabel]) as paths_as_text\n",
    "where sims <> []\n",
    "return similar as title, apoc.coll.avg(sims) as sim, sims, reduce(result=\"\", x in paths_as_text | result + reduce(inner=\"\", y in x | inner + \"\\n\"+y))  as explanation\n",
    "order by sim desc limit 4\n",
    "'''\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with driver.session(database=\"neo4j\") as session:\n",
    "  results = session.read_transaction(\n",
    "    lambda tx: tx.run(graph_similarity,\n",
    "                      uri=current_uri).data())\n",
    "\n",
    "  context = \"Related documents: \\n\\n\" + \"\\n\\n\".join([\"title: \" + record['title'] + \"\\n\" + \"explanation: \" + record['explanation'] + \"\\n\" for record in results ])\n",
    "\n",
    "driver.close()\n",
    "\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "template = \"\"\"I've read an article titled {current_article_title}.\n",
    "Tell me what should I read next and a brief description of why based only on the provided context.\n",
    "\n",
    "{context}\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "theprompt = prompt.format_prompt(current_article_title=current_title,context=context)\n",
    "\n",
    "#print(theprompt)\n",
    "\n",
    "llm(theprompt.to_messages())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
